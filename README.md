# pix2pix
This repository contains implementation of Conditional GAN model for images modality translation, described in [Image-to-Image Translation with Conditional Adversarial Networks (Isola et al. 2016)](https://arxiv.org/pdf/1611.07004.pdf)

Good pi2pix datasets can be downloaded from [here](http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/) (train.py already contains code for downloading facades/maps datasets)

pix2pix_facades.ipynb contains training on facades dataset for 800 + 200 epochs

Train:

![train_facades](https://user-images.githubusercontent.com/44977318/103275657-b6488600-49d5-11eb-9fd0-d30b89b5f0e8.jpg)

Good examples:

<img width="670" alt="image" src="https://user-images.githubusercontent.com/44977318/103275820-0b849780-49d6-11eb-9479-78f37b1fddd0.png">

<img width="662" alt="image" src="https://user-images.githubusercontent.com/44977318/103275970-628a6c80-49d6-11eb-8fae-4688284b49fd.png">

<img width="669" alt="image" src="https://user-images.githubusercontent.com/44977318/103276130-c7de5d80-49d6-11eb-98e9-9aa929f9e3db.png">
